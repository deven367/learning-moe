# learning-moe

The idea in this repository is simple

- [ ] implement a basic moe from scratch
- [ ] train a small moe (network) on a toy dataset


## note

1. An "Expert" in an MoE model is nothing but a few dense layers.
2. The gating mechanism as well is just a dense layer

